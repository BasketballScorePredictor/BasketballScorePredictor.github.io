{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction\n",
    "### Choosing the package\n",
    "This was the first project each of us have worked on that involved machine learning. Because of this we wanted to test a variety of different models to develop a breadth of knowledge. So we tried a few different models, starting with a simple linear regression and ending up utilizing a TensorFlow Sequential model. Along the way, we attempted to use a KNN model, a gradient boosted machine and a random forest. We ended up using a TensorFlow Sequential model because it produced the best mean absolute error. This was important because we want our model to predict the final score of NBA games with the least amount of error. \n",
    "\n",
    "### Models.py\n",
    "To help in the training and hyperparameterization tuning in Tensorflow we created a small package to help. This includes funcitons to help compile, fit and test models. \n",
    "\n",
    "Now we will get into the actual construction of models. Remember from the EDA, we realized there were 2 classes of variables correlated to final score, derived statisitcs and base statistics. We will begin by testing which performs better. If they perform similarily, we will go with the base statistics to keep things simple and to make deployment easier.\n",
    "\n",
    "### Overfitting\n",
    "When initially training models, there overfitting was imedietely evident. To combat this, we implemented dropout layers between each dense layer. We also implemented an Earlystop callback to stop training the model once no progress was made. Combined, these drasticlaly reduced overfitting and made it a nonfactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "from Models import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "games = pd.read_csv(\"gamesDoubled.csv\")\n",
    "games = games.iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to test different combinations of hyperparameters\n",
    "def test_models(normalizer, X_train, X_test, y_train, y_test):\n",
    "    nodes = [32, 64, 128]\n",
    "    layers = [2, 4, 6]\n",
    "    loss_func = ['mse', 'mae', 'huber']\n",
    "    for node in nodes:\n",
    "        for layer in layers:\n",
    "            for func in loss_func:\n",
    "                model = build_and_compile_model(normalizer, num_layers=layer, nodes=node,\n",
    "                                                loss_func=func)\n",
    "                fit_model(model, X_train, y_train)\n",
    "                mae = find_mae(model, X_test, y_test)\n",
    "                print(f\"layers{layer}, nodes:{node}, loss_func:{func} \\\n",
    "                    results of an MAE of {mae}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model using derived statistics\n",
    "# splitting test and train data for derived statisitcs\n",
    "X_labels_derived = ['OFF_RATING', 'AST_RATIO', 'TS_PCT' ] \n",
    "y_label = 'final_PTS'\n",
    "X_train_derived, X_test_derived, y_train_derived, y_test_derived = splitData(games, X_labels_derived, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a normalizing layer to input data\n",
    "normalizer_derived = createNormalizer(X_train_derived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test and train data for base statisitcs\n",
    "X_labels_base = ['FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'OREB', 'DREB', 'AST',\n",
    "       'STL', 'BLK', 'TO', 'PF', 'half_PTS', 'Home']\n",
    "y_label = 'final_PTS'\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = splitData(games, X_labels_base, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_base = createNormalizer(X_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers2, nodes:32, loss_func:mse                     results of an MAE of 8.46093200896631\n",
      "layers2, nodes:32, loss_func:mae                     results of an MAE of 8.393979891099647\n",
      "layers2, nodes:32, loss_func:huber                     results of an MAE of 8.395528094972407\n",
      "layers4, nodes:32, loss_func:mse                     results of an MAE of 9.073101640205318\n",
      "layers4, nodes:32, loss_func:mae                     results of an MAE of 9.09207113109542\n",
      "layers4, nodes:32, loss_func:huber                     results of an MAE of 9.814485787596379\n",
      "layers6, nodes:32, loss_func:mse                     results of an MAE of 10.033336741928446\n",
      "layers6, nodes:32, loss_func:mae                     results of an MAE of 10.364095415578047\n",
      "layers6, nodes:32, loss_func:huber                     results of an MAE of 8.600970022258126\n",
      "layers2, nodes:64, loss_func:mse                     results of an MAE of 8.395549388040006\n",
      "layers2, nodes:64, loss_func:mae                     results of an MAE of 8.401084971802398\n",
      "layers2, nodes:64, loss_func:huber                     results of an MAE of 8.398592129053245\n",
      "layers4, nodes:64, loss_func:mse                     results of an MAE of 8.402547645235977\n",
      "layers4, nodes:64, loss_func:mae                     results of an MAE of 8.497450899453687\n",
      "layers4, nodes:64, loss_func:huber                     results of an MAE of 8.459505614435486\n",
      "layers6, nodes:64, loss_func:mse                     results of an MAE of 8.648846149278144\n",
      "layers6, nodes:64, loss_func:mae                     results of an MAE of 8.492277617396276\n",
      "layers6, nodes:64, loss_func:huber                     results of an MAE of 8.47593824110314\n",
      "layers2, nodes:128, loss_func:mse                     results of an MAE of 8.39809156221453\n",
      "layers2, nodes:128, loss_func:mae                     results of an MAE of 8.38741107428053\n",
      "layers2, nodes:128, loss_func:huber                     results of an MAE of 8.358262067065812\n",
      "layers4, nodes:128, loss_func:mse                     results of an MAE of 8.470730102166247\n",
      "layers4, nodes:128, loss_func:mae                     results of an MAE of 8.382860703659723\n",
      "layers4, nodes:128, loss_func:huber                     results of an MAE of 8.461726323472268\n",
      "layers6, nodes:128, loss_func:mse                     results of an MAE of 8.733542044541391\n",
      "layers6, nodes:128, loss_func:mae                     results of an MAE of 8.450186450152705\n",
      "layers6, nodes:128, loss_func:huber                     results of an MAE of 8.446192450132253\n"
     ]
    }
   ],
   "source": [
    "# Testing the derived statistics\n",
    "# Note this cell takes awhile to run\n",
    "test_models(normalizer_derived, X_train_derived, X_test_derived, y_train_derived, y_test_derived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers2, nodes:32, loss_func:mse                     results of an MAE of 7.031172126916482\n",
      "layers2, nodes:32, loss_func:mae                     results of an MAE of 6.959156586279212\n",
      "layers2, nodes:32, loss_func:huber                     results of an MAE of 7.020774069048763\n",
      "layers4, nodes:32, loss_func:mse                     results of an MAE of 8.852753029069351\n",
      "layers4, nodes:32, loss_func:mae                     results of an MAE of 7.493286391120098\n",
      "layers4, nodes:32, loss_func:huber                     results of an MAE of 10.279730976896968\n",
      "layers6, nodes:32, loss_func:mse                     results of an MAE of 12.085956951627349\n",
      "layers6, nodes:32, loss_func:mae                     results of an MAE of 7.696864432023665\n",
      "layers6, nodes:32, loss_func:huber                     results of an MAE of 8.132665725361822\n",
      "layers2, nodes:64, loss_func:mse                     results of an MAE of 6.984552067195766\n",
      "layers2, nodes:64, loss_func:mae                     results of an MAE of 7.0066363482783185\n",
      "layers2, nodes:64, loss_func:huber                     results of an MAE of 6.977811325366169\n",
      "layers4, nodes:64, loss_func:mse                     results of an MAE of 6.9134259262218105\n",
      "layers4, nodes:64, loss_func:mae                     results of an MAE of 7.072850844830951\n",
      "layers4, nodes:64, loss_func:huber                     results of an MAE of 7.200069775007158\n",
      "layers6, nodes:64, loss_func:mse                     results of an MAE of 7.166140809649988\n",
      "layers6, nodes:64, loss_func:mae                     results of an MAE of 7.265911574971198\n",
      "layers6, nodes:64, loss_func:huber                     results of an MAE of 6.991921496432905\n",
      "layers2, nodes:128, loss_func:mse                     results of an MAE of 6.9185511510825695\n",
      "layers2, nodes:128, loss_func:mae                     results of an MAE of 6.88019439670636\n",
      "layers2, nodes:128, loss_func:huber                     results of an MAE of 6.908974113264633\n",
      "layers4, nodes:128, loss_func:mse                     results of an MAE of 7.050243012859351\n",
      "layers4, nodes:128, loss_func:mae                     results of an MAE of 6.947722537854579\n",
      "layers4, nodes:128, loss_func:huber                     results of an MAE of 6.91434483286806\n",
      "layers6, nodes:128, loss_func:mse                     results of an MAE of 7.467655836974139\n",
      "layers6, nodes:128, loss_func:mae                     results of an MAE of 7.05632726459603\n",
      "layers6, nodes:128, loss_func:huber                     results of an MAE of 7.062979167252519\n"
     ]
    }
   ],
   "source": [
    "# Testing the base statistics\n",
    "# Note this cell takes awhile to run\n",
    "test_models(normalizer_base, X_train_base, X_test_base, y_train_base, y_test_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The results\n",
    "The results were quite similar between the 2 different classes of statistics. Note that the return MAE will vary each time the above codes are run. I selected the class of data and hyperparameters based on what consistently performed best. \n",
    "\n",
    "The hyperparameters that consistently performed the best was with 2 layers of 64 nodes using the mean squared erorr as the loss function. This will be the model we construct to make our predicions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing final model\n",
    "final_model = build_and_compile_model(normalizer_base, num_layers=2, nodes=64, loss_func='mse')\n",
    "fit_model(final_model, X_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of our final model is: 7.078037761268815\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of predictions\n",
    "MAE = find_mae(final_model, X_test_base, y_test_base)\n",
    "print(\"The MAE of our final model is: {}\".format(MAE))\n",
    "test_predictions = [item[0] for item in final_model.predict(X_test_base)]\n",
    "differences = test_predictions - y_test_base\n",
    "plt.hist(differences)\n",
    "lower = np.percentile(differences, 2.5)\n",
    "upper = np.percentile(differences, 97.5)\n",
    "plt.plot((lower, upper), (0, 0), linewidth=15)\n",
    "plt.title('Distribution of Predicted Final Scores w/ 95% C.I.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finalModel/assets\n"
     ]
    }
   ],
   "source": [
    "# Saving the final model for NBA\n",
    "final_model.save('finalModelNBA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WNBA Model\n",
    "The results we got from our model trained to predict the final score of NBA predicted games wasn't performing quite to the accuracy we were hoping for. One way we tried to remedy this was to look for more data. During this process, we came across data from WNBA games. We had heard that WNBA are easier to predict so we went ahead and tried training a similar model on WNBA data and see if any improvements were made. \n",
    "\n",
    "To do this we will use the same technique used with NBA data and see if there are any noticeable differences. We will jump straight to training models with base statistics so we won't need the derived statistics in our doubled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-1dd21ee33bb2>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_games['Home_team'] = 0\n",
      "<ipython-input-6-1dd21ee33bb2>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  h_games['Home_team'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TO</th>\n",
       "      <th>PF</th>\n",
       "      <th>half_PTS</th>\n",
       "      <th>final_PTS</th>\n",
       "      <th>Home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FGM   FGA  FG3M  FG3A  FTM  FTA  OREB  DREB   AST  STL  BLK    TO    PF  \\\n",
       "0  13.0  32.0   2.0   3.0  6.0  8.0   5.0  10.0   8.0  4.0  1.0  11.0  10.0   \n",
       "1  18.0  36.0   3.0   7.0  3.0  3.0   7.0  14.0  13.0  3.0  1.0  10.0  12.0   \n",
       "2  13.0  44.0   7.0  12.0  7.0  8.0   9.0  11.0   9.0  2.0  2.0   4.0   6.0   \n",
       "3  18.0  38.0   3.0  10.0  6.0  6.0   4.0  13.0  14.0  7.0  3.0   5.0   8.0   \n",
       "4  11.0  34.0   3.0  12.0  6.0  6.0   5.0  13.0   6.0  2.0  3.0  11.0   7.0   \n",
       "\n",
       "   half_PTS  final_PTS  Home  \n",
       "0      34.0       59.0     1  \n",
       "1      42.0       91.0     1  \n",
       "2      40.0       80.0     1  \n",
       "3      45.0       63.0     1  \n",
       "4      31.0       71.0     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens_games = pd.read_csv(\"wnba_half_stats.csv\")\n",
    "womens_games = womens_games[womens_games['a_final_PTS'] >= 20]\n",
    "womens_games = womens_games[womens_games['a_PLUS_MINUS'].notna()]\n",
    "labels = ['FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'OREB', 'DREB', 'AST', 'STL', 'BLK', 'TO',\n",
    "          'PF', 'half_PTS', 'final_PTS']\n",
    "a_labels = ['a_'+label for label in labels]\n",
    "h_labels = ['h_'+label for label in labels]\n",
    "new_columns = h_labels + a_labels\n",
    "womens_games = womens_games[new_columns]\n",
    "womens_games = womens_games.drop_duplicates()\n",
    "new_labels = ['FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'OREB', 'DREB', 'AST', 'STL', 'BLK', 'TO',\n",
    "          'PF', 'half_PTS', 'final_PTS', 'Home']\n",
    "a_games = womens_games[a_labels]\n",
    "a_games['Home_team'] = 0\n",
    "a_games.columns = new_labels\n",
    "h_games = womens_games[h_labels]\n",
    "h_games['Home_team'] = 1\n",
    "h_games.columns = new_labels\n",
    "womens_games = h_games.append(a_games)\n",
    "womens_games.to_csv(\"womensGamesDoubled.csv\")\n",
    "womens_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_womens = womens_games.columns.drop('final_PTS')\n",
    "y_womens = 'final_PTS'\n",
    "X_train_womens, X_test_womens, y_train_womens, y_test_womens = splitData(womens_games, X_womens, y_womens)\n",
    "normalizer_womens = createNormalizer(X_train_womens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers2, nodes:32, loss_func:mse                     results of an MAE of 7.2965599738227\n",
      "layers2, nodes:32, loss_func:mae                     results of an MAE of 9.915652330186632\n",
      "layers2, nodes:32, loss_func:huber                     results of an MAE of 9.6822886912028\n",
      "layers4, nodes:32, loss_func:mse                     results of an MAE of 8.41173334757487\n",
      "layers4, nodes:32, loss_func:mae                     results of an MAE of 9.989475267198351\n",
      "layers4, nodes:32, loss_func:huber                     results of an MAE of 12.299133292304145\n",
      "layers6, nodes:32, loss_func:mse                     results of an MAE of 11.404505174424914\n",
      "layers6, nodes:32, loss_func:mae                     results of an MAE of 9.746273820665147\n",
      "layers6, nodes:32, loss_func:huber                     results of an MAE of 9.888686684502495\n",
      "layers2, nodes:64, loss_func:mse                     results of an MAE of 9.25046979268392\n",
      "layers2, nodes:64, loss_func:mae                     results of an MAE of 9.95101424323188\n",
      "layers2, nodes:64, loss_func:huber                     results of an MAE of 9.003948008219401\n",
      "layers4, nodes:64, loss_func:mse                     results of an MAE of 9.457218051486546\n",
      "layers4, nodes:64, loss_func:mae                     results of an MAE of 6.090366363525391\n",
      "layers4, nodes:64, loss_func:huber                     results of an MAE of 8.834490763346354\n",
      "layers6, nodes:64, loss_func:mse                     results of an MAE of 7.538226165771484\n",
      "layers6, nodes:64, loss_func:mae                     results of an MAE of 8.46306514316135\n",
      "layers6, nodes:64, loss_func:huber                     results of an MAE of 7.005453270806207\n",
      "layers2, nodes:128, loss_func:mse                     results of an MAE of 5.25768435160319\n",
      "layers2, nodes:128, loss_func:mae                     results of an MAE of 5.072282392713759\n",
      "layers2, nodes:128, loss_func:huber                     results of an MAE of 5.436161126030816\n",
      "layers4, nodes:128, loss_func:mse                     results of an MAE of 5.513529315524631\n",
      "layers4, nodes:128, loss_func:mae                     results of an MAE of 5.95423833211263\n",
      "layers4, nodes:128, loss_func:huber                     results of an MAE of 6.297181862725152\n",
      "layers6, nodes:128, loss_func:mse                     results of an MAE of 6.088196055094401\n",
      "layers6, nodes:128, loss_func:mae                     results of an MAE of 7.789698308308919\n",
      "layers6, nodes:128, loss_func:huber                     results of an MAE of 6.241215633816189\n"
     ]
    }
   ],
   "source": [
    "test_models(normalizer_womens, X_train_womens, X_test_womens, y_train_womens, y_test_womens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WNBA Results\n",
    "The best performing model for predicting WNBA games had 4 layers, 128 nodes and used the mean squared error loss function. We will train a model with the selected hyperparameters and save it so that we can deploy it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_WNBAModel/assets\n"
     ]
    }
   ],
   "source": [
    "final_WNBAModel = build_and_compile_model(normalizer_womens, num_layers=4, nodes=128, loss_func='mse')\n",
    "fit_model(final_WNBAModel, X_train_womens, y_train_womens)\n",
    "final_WNBAModel.save(\"final_WNBAModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.285559675428602"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens_mae = find_mae(final_WNBAModel, X_test_womens, y_test_womens)\n",
    "womens_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07113609098896567"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womens_mae / np.mean(y_train_womens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06836121960191514"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE / np.mean(y_train_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Conclusion \n",
    "Now we have our final model that we can use to predict final score. We can now go forward with implementing the models we created. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
